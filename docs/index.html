<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Semiautonomous Systems</title>
  <meta name="description" content="Digital accountability infrastructure for AI crawlers. Rules of engagement that sites can enforce." />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800&family=Red+Hat+Display:wght@600;700;800&display=swap" rel="stylesheet">
  <style>
    :root { --bg:#0b0f14; --text:#e5e7eb; --muted:#94a3b8; --accent:#b72115; --border:#1f2937; }
    *{box-sizing:border-box}
    body{margin:0;background:var(--bg);color:var(--text);font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Cantarell,Noto Sans,Helvetica Neue,Arial,sans-serif}
    .container{width:min(1100px,92%);margin-inline:auto;padding:40px 0}
    h1{font-family:'Red Hat Display',Inter,system-ui,sans-serif;font-weight:800;text-transform:uppercase;letter-spacing:.5px;font-size:clamp(44px,6vw,72px);margin:0}
    h2{font-family:'Red Hat Display',Inter,system-ui,sans-serif;font-weight:700;font-size:clamp(32px,4vw,48px);margin:0 0 20px 0}
    h3{font-family:'Red Hat Display',Inter,system-ui,sans-serif;font-weight:600;font-size:clamp(24px,3vw,32px);margin:0 0 12px 0}
    p{color:var(--muted);max-width:720px;line-height:1.6;margin:0 0 16px 0}
    .grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(220px,1fr));gap:16px;margin-top:30px}
    .card{border:1px solid var(--border);border-radius:14px;padding:16px;background:linear-gradient(180deg,rgba(18,24,33,.7),rgba(18,24,33,.4))}
    a.btn{display:inline-block;margin-top:14px;padding:10px 14px;border-radius:10px;background:linear-gradient(135deg,#7c3aed,#22d3ee);color:#fff;text-decoration:none;font-weight:600}
    a.btn-secondary{display:inline-block;margin-top:14px;margin-left:12px;padding:10px 14px;border-radius:10px;border:1px solid var(--accent);color:var(--accent);text-decoration:none;font-weight:600;transition:all 0.2s}
    a.btn-secondary:hover{background:var(--accent);color:#fff}
    .muted{color:var(--muted)}
    .hero{position:relative;min-height:58vh;display:flex;align-items:center}
    .hero::before{content:"";position:absolute;inset:0;background:
      radial-gradient(800px 500px at -10% -20%, rgba(183,33,21,.18), transparent 60%),
      radial-gradient(900px 700px at 110% 120%, rgba(183,33,21,.12), transparent 60%),
      linear-gradient(180deg, #0b0f14, #0b0f14);
    }
    .hero::after{content:"";position:absolute;inset:0;background:linear-gradient(180deg,rgba(0,0,0,.65),rgba(183,33,21,.22));}
    .hero-inner{position:relative;z-index:1;width:min(1100px,92%);margin-inline:auto}
    .cta{display:inline-block;margin-top:18px;padding:12px 16px;border-radius:10px;background:var(--accent);color:#fff;text-decoration:none;font-weight:700}
    .section{padding:60px 0}
    ul{list-style:none;padding:0;margin:20px 0}
    ul li{margin:12px 0;padding-left:24px;position:relative;color:var(--muted)}
    ul li::before{content:"—";position:absolute;left:0;color:var(--accent)}
    .callout{padding:20px;border-left:3px solid var(--accent);background:rgba(183,33,21,.1);margin:24px 0;border-radius:4px}
  </style>
</head>
<body>
  <section class="hero" aria-label="Semiautonomous Systems">
    <div class="hero-inner">
      <h1>Semiautonomous Systems</h1>
      <p style="font-size:1.2em;margin-top:20px">Rules of engagement for AI crawlers.</p>
      <div style="margin-top:24px">
        <a class="cta" href="mailto:venom@semiautonomous.systems">Talk to us</a>
        <a class="btn-secondary" href="/venom/">Learn about VENOM</a>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2>The shift</h2>
      <p>AI crawlers extract value from public content without sending users back. Major AI companies scrape billions of pages to train models that compete directly with content creators.</p>
      <p>Publishers like The New York Times and CNN have blocked crawlers like GPTBot and CCBot, but blocking is binary. You can't say "yes for search indexing, no for training" or "yes with attribution, no without."</p>
      <p>Existing tools don't give real leverage:</p>
      <ul>
        <li><strong>No enforceable rules:</strong> robots.txt is voluntary. Crawlers can ignore it with no technical consequence.</li>
        <li><strong>No instrumentation:</strong> Can't express nuanced preferences like "search vs training" or "with attribution vs without."</li>
        <li><strong>No leverage:</strong> Legal boilerplate doesn't change behavior. Violations are hard to detect and harder to prove.</li>
      </ul>
      <p>Content creators bear hosting and bandwidth costs while AI companies extract value without compensation.</p>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2>Our thesis</h2>
      <p>Semiautonomous Systems builds infrastructure that lets sites set, enforce, and measure rules of engagement for AI crawlers. The goal is to rebalance power so creators and publishers have a say in how their content is used.</p>
      <p>We believe that rules of engagement should be:</p>
      <ul>
        <li><strong>Expressible:</strong> Sites can declare nuanced preferences—not just "allow" or "disallow," but "allow for search with attribution," "rate-limit training crawls," or "block unauthorized commercial use."</li>
        <li><strong>Enforceable:</strong> Technical controls at the edge that make violating rules costly and unattractive. Honest, contracted access becomes easier and cheaper than cheating.</li>
        <li><strong>Measurable:</strong> Instrumentation that tracks compliance, detects violations, and provides evidence for accountability.</li>
      </ul>
      <p>This shifts the economics: instead of "scrape everything and ask forgiveness later," crawlers must respect declared preferences or face technical consequences. Sites gain leverage through protocol reality, not just legal text.</p>
      <div class="callout">
        <p style="margin:0;font-weight:600;color:var(--text)">From "please don't" to protocol reality.</p>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2>What we're building</h2>
      <p>We ship infrastructure that makes rules of engagement real: technical controls, measurement, and detection.</p>
      <ul>
        <li><strong>Technical controls:</strong> Edge-native enforcement at CDN or reverse proxy layers. Rate limiting, blocking, and protective responses that stop violators before they reach your application.</li>
        <li><strong>Measurement:</strong> Analytics showing who's crawling, how often, and whether they're respecting your preferences. Evidence for accountability.</li>
        <li><strong>Detection:</strong> Multi-signal fingerprinting identifies AI crawlers even when they rotate user agents or use residential proxies. Behavioral analysis catches stealth patterns.</li>
      </ul>
      <p>Our first product, <a href="/venom/" style="color:var(--accent);text-decoration:underline">VENOM</a>, brings these ideas to individual content surfaces.</p>
      <p style="margin-top:20px"><a href="/venom/" class="btn-secondary">Learn more on the VENOM page</a></p>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <p style="font-size:1.1em;max-width:none">We're building this infrastructure with design partners: content sites, publishers, and platforms who want to experiment with rules of engagement and anti-scraping strategy. If you're dealing with unauthorized AI crawlers, want to enforce opt-out preferences, or need better visibility into who's accessing your content, we'd like to hear from you.</p>
      <p style="margin-top:30px"><a class="cta" href="mailto:venom@semiautonomous.systems">Get in touch</a></p>
    </div>
  </section>
</body>
</html>

