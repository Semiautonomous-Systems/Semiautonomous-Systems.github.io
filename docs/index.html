<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Semiautonomous Systems</title>
  <meta name="description" content="Digital accountability infrastructure for AI crawlers. Rules of engagement that sites can enforce." />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800&family=Red+Hat+Display:wght@600;700;800&display=swap" rel="stylesheet">
  <style>
    :root { --bg:#0b0f14; --text:#e5e7eb; --muted:#94a3b8; --accent:#b72115; --border:#1f2937; }
    *{box-sizing:border-box}
    body{margin:0;background:var(--bg);color:var(--text);font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Cantarell,Noto Sans,Helvetica Neue,Arial,sans-serif}
    .container{width:min(1100px,92%);margin-inline:auto;padding:40px 0}
    h1{font-family:'Red Hat Display',Inter,system-ui,sans-serif;font-weight:800;text-transform:uppercase;letter-spacing:.5px;font-size:clamp(44px,6vw,72px);margin:0}
    h2{font-family:'Red Hat Display',Inter,system-ui,sans-serif;font-weight:700;font-size:clamp(32px,4vw,48px);margin:0 0 20px 0}
    h3{font-family:'Red Hat Display',Inter,system-ui,sans-serif;font-weight:600;font-size:clamp(24px,3vw,32px);margin:0 0 12px 0}
    p{color:var(--muted);max-width:720px;line-height:1.6;margin:0 0 16px 0}
    .grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(220px,1fr));gap:16px;margin-top:30px}
    .card{border:1px solid var(--border);border-radius:14px;padding:16px;background:linear-gradient(180deg,rgba(18,24,33,.7),rgba(18,24,33,.4))}
    a.btn{display:inline-block;margin-top:14px;padding:10px 14px;border-radius:10px;background:linear-gradient(135deg,#7c3aed,#22d3ee);color:#fff;text-decoration:none;font-weight:600}
    a.btn-secondary{display:inline-block;margin-top:14px;margin-left:12px;padding:10px 14px;border-radius:10px;border:1px solid var(--accent);color:var(--accent);text-decoration:none;font-weight:600;transition:all 0.2s}
    a.btn-secondary:hover{background:var(--accent);color:#fff}
    .muted{color:var(--muted)}
    .hero{position:relative;min-height:58vh;display:flex;align-items:center}
    .hero::before{content:"";position:absolute;inset:0;background:
      radial-gradient(800px 500px at -10% -20%, rgba(183,33,21,.18), transparent 60%),
      radial-gradient(900px 700px at 110% 120%, rgba(183,33,21,.12), transparent 60%),
      linear-gradient(180deg, #0b0f14, #0b0f14);
    }
    .hero::after{content:"";position:absolute;inset:0;background:linear-gradient(180deg,rgba(0,0,0,.65),rgba(183,33,21,.22));}
    .hero-inner{position:relative;z-index:1;width:min(1100px,92%);margin-inline:auto}
    .cta{display:inline-block;margin-top:18px;padding:12px 16px;border-radius:10px;background:var(--accent);color:#fff;text-decoration:none;font-weight:700}
    .section{padding:60px 0}
    ul{list-style:none;padding:0;margin:20px 0;max-width:720px}
    ul li{margin:12px 0;padding-left:20px;position:relative;color:var(--muted)}
    ul li::before{content:"-";position:absolute;left:0;color:var(--accent);font-weight:700}
    .callout{padding:20px;border-left:3px solid var(--accent);background:rgba(183,33,21,.1);margin:24px 0;border-radius:4px}
  </style>
</head>
<body>
  <section class="hero" aria-label="Semiautonomous Systems">
    <div class="hero-inner">
      <h1>Semiautonomous Systems</h1>
      <p style="font-size:1.2em;margin-top:20px">Rules of engagement for AI crawlers that sites can actually enforce.</p>
      <div style="margin-top:24px">
        <a class="cta" href="mailto:venom@semiautonomous.systems">Talk to us</a>
        <a class="btn-secondary" href="/venom/">Learn about VENOM</a>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2>The shift</h2>
      <p>AI crawlers extract value from public content without sending users back. Major AI companies scrape billions of pages to train models that compete directly with content creators. The economics are inverted: content creators bear hosting and bandwidth costs while AI companies extract value without compensation or even attribution.</p>
      <p>Publishers like The New York Times and CNN have responded by blocking crawlers like GPTBot and CCBot. But blocking is binary and blunt. You can't say "yes for search indexing, no for training." The tools available today don't give sites real leverage.</p>
      <p>The robots.txt file is a standard that lets sites declare which crawlers can access which parts of their site. But it's voluntary and can be ignored with no technical consequence. There's no way to express nuanced preferences like "search vs training." Legal boilerplate and terms of service don't change crawler behavior, and violations are hard to detect and harder to prove.</p>
      <p>Existing tools fail in three ways:</p>
      <ul>
        <li><strong>No enforceable rules:</strong> robots.txt is voluntary</li>
        <li><strong>No instrumentation:</strong> Can't express nuanced preferences</li>
        <li><strong>No leverage:</strong> Legal boilerplate doesn't change behavior</li>
      </ul>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2>Our thesis</h2>
      <p>Semiautonomous Systems builds infrastructure that lets sites set, enforce, and measure rules of engagement for AI crawlers. The goal is to rebalance power so creators and publishers have a say in how their content is used.</p>
      <p>We believe that rules of engagement should be expressible, enforceable, and measurable. Sites should be able to declare nuanced preferences beyond simple "allow" or "disallow."</p>
      <p>These preferences need technical controls at the edge that make violating rules costly and unattractive. Honest, contracted access should become easier and cheaper than cheating. And there must be instrumentation that tracks compliance, detects violations, and provides evidence for accountability.</p>
      <p>This shifts the economics: instead of "scrape everything and ask forgiveness later," crawlers must respect declared preferences or face technical consequences. Sites gain leverage through protocol reality, not just legal text.</p>
      <ul>
        <li><strong>Expressible:</strong> Sites can declare nuanced preferences beyond simple allow or disallow.</li>
        <li><strong>Enforceable:</strong> Technical controls at the edge make violating rules costly and unattractive.</li>
        <li><strong>Measurable:</strong> Instrumentation tracks compliance, detects violations, and provides evidence for accountability.</li>
      </ul>
      <div class="callout">
        <p style="margin:0;font-weight:600;color:var(--text)">From "please don't" to protocol reality.</p>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <h2>What we're building</h2>
      <p>We ship infrastructure that makes rules of engagement real through technical controls, measurement, and detection.</p>
      <ul>
        <li><strong>Technical controls:</strong> Edge-native enforcement at CDN or reverse proxy layers that stops violators before they reach your application. This preserves latency budgets for real users while enforcing your preferences.</li>
        <li><strong>Measurement:</strong> Analytics showing who's crawling, how often, and whether they're respecting your preferences. This evidence supports accountability and helps you optimize your rules over time.</li>
        <li><strong>Detection:</strong> Multi-signal fingerprinting identifies AI crawlers even when they rotate user agents or use residential proxies. Behavioral analysis catches stealth patterns that simple detection methods miss.</li>
      </ul>
      <p>Our first product, <a href="/venom/" style="color:var(--accent);text-decoration:underline">VENOM</a>, brings these ideas to individual content surfaces.</p>
      <p style="margin-top:20px"><a href="/venom/" class="btn-secondary">Learn more on the VENOM page</a></p>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <p style="font-size:1.1em;max-width:none">We're building this infrastructure with design partners: content sites, publishers, and platforms who want to experiment with rules of engagement and anti-scraping strategy. If you're dealing with unauthorized AI crawlers, want to enforce opt-out preferences, or need better visibility into who's accessing your content, we'd like to hear from you.</p>
      <p style="margin-top:30px"><a class="cta" href="mailto:venom@semiautonomous.systems">Get in touch</a></p>
    </div>
  </section>
</body>
</html>

